# Boostcamp Machine Reading Comprehension Competition
## **Table of contents**

1. [Introduction](#introduction)
2. [Project Outline](#project-outline)
3. [Solution](#solution)
4. [How to Use](#how-to-use)

# 1. Introduction  
<br/>
<p align="center">
   <img src="https://user-images.githubusercontent.com/62708568/136650411-a9923f11-eb89-4832-8c86-89ee48c62f69.png" style="width:800px;"/>
</p>

<br/>


## â˜• ì¡°ì§€KLUEë‹ˆ

## **ê°œìš”**

1. Introduction
2. Project Outline
3. Solution
4. How to Use

# 1. Introduction

[ğŸ”… Members](https://www.notion.so/bcc26f407b22470a9cbcaa6a238b573f)

### ğŸ”… Contribution

`ê¹€ë³´ì„±` Modeling(MaskedLM with Bi-LSTM, MaskedLM with Autoencoder)â€¢Reference searchingâ€¢Paper implementationâ€¢Ensembleâ€¢github management

`ê¹€ì§€í›„`  

`ê¹€í˜œìˆ˜` Reference Searchingâ€¢ElasticSearch config & Optimizationâ€¢Data Processingâ€¢Sparse/Dense Retrievalâ€¢Re-ranking MRC outputs w/ Retrieval

`ë°•ì´ì‚­` Reference Searchingâ€¢Github management

`ì´ë‹¤ê³¤` Data Processingâ€¢Generative MRC

`ì „ë¯¸ì›` Data Preprocessingâ€¢Add Elastic Search into baselineâ€¢Re-ranking MRC outputs w/ Retrievalâ€¢Ensemble

`ì •ë‘í•´` Data Explorationâ€¢Baseline Abstractionâ€¢Sparse/Dense Retrieverâ€¢Reader Model Searchingâ€¢Data Augmentationâ€¢MRC Hyperparameter Tuningâ€¢Pre/Postprocessing

# 2. Project Outline

- Task : Extractive-based MRCë¥¼ ìœ„í•œ ODQA ëª¨ë¸ êµ¬ì¶•
- Date : 2021.10.12 - 2021.11.04 (4 weeks)
- Description : **ë³¸ ODQA ëŒ€íšŒì—ì„œ ìš°ë¦¬ê°€ ë§Œë“¤ ëª¨ë¸ì€ two-stage**ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.Â **ì²« ë‹¨ê³„ëŠ” ì§ˆë¬¸ì— ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì•„ì£¼ëŠ” "retriever"**Â ë‹¨ê³„ì´ê³ ,Â **ë‹¤ìŒìœ¼ë¡œëŠ” ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì½ê³  ì ì ˆí•œ ë‹µë³€ì„ ì°¾ê±°ë‚˜ ë§Œë“¤ì–´ì£¼ëŠ” "reader"**Â ë‹¨ê³„ì…ë‹ˆë‹¤. ë‘ ê°€ì§€ ë‹¨ê³„ë¥¼ ê°ê° êµ¬ì„±í•˜ê³  ê·¸ê²ƒë“¤ì„ ì ì ˆíˆ í†µí•©í•˜ê²Œ ë˜ë©´, ì–´ë ¤ìš´ ì§ˆë¬¸ì„ ë˜ì ¸ë„ ë‹µë³€ì„ í•´ì£¼ëŠ” ODQA ì‹œìŠ¤í…œì„ ì—¬ëŸ¬ë¶„ë“¤ ì†ìœ¼ë¡œ ì§ì ‘ ë§Œë“¤ì–´ë³´ê²Œ ë©ë‹ˆë‹¤.
- Train : 3,952ê°œ
- Validation : 240ê°œ
- Test : 600ê°œ

### ğŸ† Final Score

ëŒ€íšŒ ì‚¬ì´íŠ¸ : [AI stage](https://stages.ai/competitions/75/overview/description)

## **Hardware**

AI stageì—ì„œ ì œê³µí•œ server, GPU

- GPU: V100

# 3. Solution

### KEY POINT

- DPR ë…¼ë¬¸ì˜ Gold ë°©ì‹ì˜ Dense Retriever ëª¨ë¸ì„ ì°¨ìš©í•´ elasticsearchì™€ ê²°í•©í•˜ì—¬ retriever ëª¨ë¸ êµ¬í˜„
- Data Augmentationì„ í†µí•´ ì§€ë¬¸ì˜ ê¸¸ì´ë¥¼ ëŠ˜ë¦° í›„ í•™ìŠµ ë°ì´í„°ë¡œ ì´ìš©
- ëŒ€ëŸ‰ì˜ í•œêµ­ì–´ ë°ì´í„°ë¡œ ì‚¬ì „í•™ìŠµ ë˜ì–´ ìˆëŠ” klue/roberta-large ëª¨ë¸ì„ ë¦¬ë” ëª¨ë¸ë¡œ ì‚¬ìš©

### Checklist

- [x]  EDA
- [x]  Data Preprocessing(`special character removal`, `getting answer spans' start position with special character tokens`)
- [x]  Data Augmentation(`Back translation`, `Question generation`)
- [x]  Data Postprocessing
- [x]  Experimental Logging (`WandB`)
- [x]  Retrieval (`dense -- FAISS,using simple dual-encoders`, `sparse -- TF-IDF,BM25,Elastic search`)
- [x]  Custom Model Architecture(`Roberta with BiLSTM`, `Roberta with Autoencoder`)
- [x]  Re-ranker (`changing scoring function using BERTserini`)
- [x]  Ensemble
- [ ]  K-fold cross validation
- [ ]  Shorten inference time when using elastic search

[Evaluation](https://www.notion.so/b3aac65c45924c378f0ec07f7b05a38a)

# 4. How to Use

## **Installation**

ë‹¤ìŒê³¼ ê°™ì€ ëª…ë ¹ì–´ë¡œ í•„ìš”í•œ librariesë¥¼ ë‹¤ìš´ ë°›ìŠµë‹ˆë‹¤.

`pip install -r requirements.txt`

Elasticsearch ëª¨ë“ˆ (ì¶œì²˜ : [ì„œì¤‘ì› ë©˜í† ë‹˜ ê¹ƒí—ˆë¸Œ](https://github.com/thejungwon/search-engine-tutorial))

`apt-get update && apt-get install -y gnupg2`

`wget -qO - [https://artifacts.elastic.co/GPG-KEY-elasticsearch](https://artifacts.elastic.co/GPG-KEY-elasticsearch) | apt-key add -`

`apt-get install apt-transport-https`

`echo "deb [https://artifacts.elastic.co/packages/7.x/apt](https://artifacts.elastic.co/packages/7.x/apt) stable main" | tee /etc/apt/sources.list.d/elastic-7.x.list`

`apt-get update && apt-get install elasticsearch`

`service elasticsearch start`

`cd /usr/share/elasticsearch`

`bin/elasticsearch-plugin install analysis-nori`

`service elasticsearch restart`

`pip install elasticsearch`

BM25 ëª¨ë“ˆ

`pip install rank_bm25`

Google deep_translator ëª¨ë“ˆ

`pip install -U deep-translator`

## **Dataset**

íŒŒì¼: data/train_dataset/train, data/train_dataset/validation, data/test_dataset/validation 

## **Data Analysis**

íŒŒì¼: 

## **Data preprocessing**

íŒŒì¼: 

## **Modeling**

íŒŒì¼: train.py, inference.py, 

## **Ensemble**

íŒŒì¼: mixing_bowl.ipynb, mixing_bowl (1).ipynb

## Directory

```
.
â”œâ”€â”€ mrc-level2-nlp-07
|    â”œâ”€â”€ code
â”‚        â”œâ”€â”€ outputs
â”‚        â”œâ”€â”€ dense_encoder
â”‚        â”œâ”€â”€ retriever
|    â”œâ”€â”€ data
â”‚        â”œâ”€â”€ train_dataset
|            â”œâ”€â”€ train
|            â”œâ”€â”€ validation
â”‚        â”œâ”€â”€ test_dataset
|            â”œâ”€â”€ validation
|        â”œâ”€â”€ wikipedia_passages.json
```

- `code` íŒŒì¼ ì•ˆì—ëŠ” ê°ê° **data preprocessing** â€¢ **train** â€¢ **inference**ê°€ ê°€ëŠ¥í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë“¤ì–´ìˆìŠµë‹ˆë‹¤.
- `train.py`ë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´ logs, results, best_model í´ë”ì— ê²°ê³¼ë“¤ì´ ì €ì¥ë©ë‹ˆë‹¤.
- ì‚¬ìš©ìëŠ” ì „ì²´ ì½”ë“œë¥¼ ë‚´ë ¤ë°›ì€ í›„, argument ì˜µì…˜ì„ ì§€ì •í•˜ì—¬ ê°œë³„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë¸ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
